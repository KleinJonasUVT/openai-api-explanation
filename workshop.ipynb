{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/favicon.png\" alt=\"Tilburg.ai logo\" style=\"float: left; margin-right: 10px;\" width=\"40\"/>\n",
    "\n",
    "# Tilburg.ai — OpenAI API Workshop\n",
    "\n",
    "### Introduction\n",
    "\n",
    "Welcome to the **OpenAI API Workshop**.\n",
    "\n",
    "In this session, we’ll start with a brief introduction to APIs and go over some essential programming concepts. We'll use a simple analogy to help explain how different models in the OpenAI API work, and we’ll carry that analogy throughout the workshop.\n",
    "\n",
    "You’ll learn the building blocks for using generative AI in research. We’ll also cover important topics like data privacy and security when working with OpenAI API's.\n",
    "\n",
    "By the end of this workshop, you will be able to:\n",
    "- Create an OpenAI account and set up your API key\n",
    "- Understand how to send and receive requests using the OpenAI API\n",
    "- Use different models such as text generation-, speech-, and embeddings models\n",
    "- Be aware of costs, limitations, and ethical considerations\n",
    "\n",
    "Let’s get started.\n",
    "\n",
    "--- \n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "Before joining the workshop, make sure you have the following ready:\n",
    "\n",
    "- A free [OpenAI account](https://platform.openai.com/signup)\n",
    "- A code editor installed on your computer, such as:\n",
    "  - **RStudio** – [Install guide via Tilburg Science Hub](https://tilburgsciencehub.com/topics/computer-setup/software-installation/rstudio/r/)\n",
    "  - **Visual Studio Code (VS Code)** – [Install guide via Tilburg Science Hub](https://tilburgsciencehub.com/topics/Computer-Setup/software-installation/IDE/vscode/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1️. Your First OpenAI API Call\n",
    "\n",
    "We’ll begin with the most basic way to interact with OpenAI's GPT model.  \n",
    "To make it intuitive, we’ll use a simple **restaurant analogy**:\n",
    "\n",
    "- **You (Customer):** The person making the request  \n",
    "- **OpenAI API (Waiter):** The messenger that delivers your request  \n",
    "- **GPT Model (Chef):** The system that prepares and returns your response\n",
    "\n",
    "<div style=\"text-align: center; margin: 1em 0;\">\n",
    "  <img src=\"images/image_01.png\" alt=\"Restaurant Analogy\" width=\"400\"/>\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Every good restaurant needs a reservation, and in our case, that reservation is your API key, which gives you access to place an order with the model._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Setting Up Your API Key\n",
    "\n",
    "Before making your first API call, follow these steps (**Need help seeing it in action?** Watch the video [walkthrough](video/workshop-API-key.mp4)):\n",
    "\n",
    "##### 1. **Get Your API Key**\n",
    "  - Use the following [link](https://platform.openai.com/api-keys) and login  \n",
    "  - Click `Create new secret key`  \n",
    "  - Copy the key  \n",
    "    - It looks like this: \"sk-...\" (keep it safe! You retrieve it only once!)\n",
    "\n",
    "##### 2. **Create a `.env` File**\n",
    "  - In the same folder where your `.ipynb` (notebook) file is, create a new file called `.env`  \n",
    "    - _Yes, the name starts with a dot and has no file extension._  \n",
    "  - Open the .env file and paste this line:\n",
    "  \n",
    "    ```bash\n",
    "    OPENAI_API_KEY=\"paste your key here\"\n",
    "    ```\n",
    "\n",
    "    - Replace `paste your key here` with the key you got from OpenAI.  \n",
    "      This keeps your API-key private and out of your code, because if the key is written directly in your code, someone else could copy it and use your OpenAI account (which might cost you money or get your access blocked).\n",
    "\n",
    "##### 3. **Install the Required Packages**  \n",
    "Open your terminal (or a cell in your notebook) and run these commands:\n",
    "\n",
    "```bash\n",
    "pip install python-dotenv  # Terminal\n",
    "%pip install python-dotenv  # Jupyter Notebook\n",
    "```\n",
    "\n",
    "##### 4. **Use the Key in Your Code**  \n",
    "Add this to the top of Notebook:\n",
    "\n",
    "```python\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Loads the .env file\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")  # Gets your key securely\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "Now you're ready to use the OpenAI API securely in your code!\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API Call\n",
    "\n",
    "We have our access (reservation = API Key) to the restaurant!\n",
    "\n",
    "From here, we can place our order (prompt) and see what the chef (the model) sends us back. \n",
    "Let's make a simple API call now to see how everything comes together.\n",
    "\n",
    "1. Set up the connection to OpenAI (like finding a restaurant)  \n",
    "2. Create a simple prompt (like placing an order)  \n",
    "3. Get the response (like receiving your meal)\n",
    "\n",
    "This is the simplest form of an API call — no streaming, no advanced parameters — just a basic request and a direct response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment and run if not already installed)\n",
    "#%pip install python-dotenv\n",
    "#%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waiter: This is the OpenAI API. You talk to it using the 'openai' Python package.\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Set your OpenAI API key (replace with your actual key or use an environment variable)\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from the AI (Chef):\n",
      "Sure! Photosynthesis is the way plants make their own food.\n",
      "\n",
      "Here’s how it works, in simple terms:\n",
      "\n",
      "1. **Plants take in sunlight** through their leaves.\n",
      "2. **They also take in carbon dioxide** from the air and **water** from the soil.\n",
      "3. **With the help of sunlight,** they use these ingredients to make **food (sugar)** for themselves.\n",
      "4. As a result, **they release oxygen** back into the air.\n",
      "\n",
      "So, in short:\n",
      "**Plants use sunlight, carbon dioxide, and water to make their own food, and they give us oxygen in return!**\n"
     ]
    }
   ],
   "source": [
    "# Customer: This is YOU (or your app). You decide what to ask.\n",
    "prompt = \"Explain photosynthesis in simple terms.\"\n",
    "\n",
    "# Chef: This is the AI model (like GPT-4). It prepares the response based on your request.\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    input=prompt\n",
    ")\n",
    "\n",
    "# The response is delivered back to the customer (you)\n",
    "result = response.output_text\n",
    "print(\"Response from the AI (Chef):\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Principles\n",
    "\n",
    "---\n",
    "\n",
    "#### Looping — _“Ordering Again and Again”_\n",
    "\n",
    "##### In the Restaurant Metaphor:\n",
    "\n",
    "Imagine you're really hungry and want to **order multiple dishes**, one after another:\n",
    "\n",
    "* First: you ask for spaghetti.\n",
    "* Then: you ask for a drink.\n",
    "* Then: dessert.\n",
    "\n",
    "That’s **looping**, doing something **over and over again**, usually **with slight changes**.\n",
    "\n",
    "<div style=\"text-align: center; margin: 1em 0;\">\n",
    "  <img src=\"images/image_02.png\" alt=\"Restaurant Analogy\" width=\"400\"/>\n",
    "</div>\n",
    "\n",
    "##### In Programming/API Terms:\n",
    "\n",
    "Looping is when your program:\n",
    "\n",
    "* Sends **multiple API requests** in a row.\n",
    "* Often in a **`for` loop** or a **`while` loop**.\n",
    "* Each request might ask a different question or use different data.\n",
    "\n",
    "**Why It’s Useful:**\n",
    "* Process a list of texts automatically (e.g., summarizing 100 articles).\n",
    "* Translate a batch of messages.\n",
    "* Chat with the model in turns.\n",
    "\n",
    "\n",
    "**A Quick Look at Loops in Python** - Before we start sending multiple questions to the API, let’s look at how Python handles **repeating tasks** using a loop.\n",
    "Here’s a list of questions we might want to ask the AI. Instead of writing separate code for each one, we can use a **`for` loop** to go through them one by one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretend we're asking the AI...\n",
      "Question: What is 1 + 1? \n",
      "\n",
      "Pretend we're asking the AI...\n",
      "Question: What is the opposite of up? \n",
      "\n",
      "Pretend we're asking the AI...\n",
      "Question: What is the capital of France? \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Basic Python loop — no API yet\n",
    "questions = [\n",
    "    \"What is 1 + 1?\",\n",
    "    \"What is the opposite of up?\",\n",
    "    \"What is the capital of France?\"\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    print(\"Pretend we're asking the AI...\")\n",
    "    print(\"Question:\", q, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This loop**:\n",
    "- Goes through the list of questions\n",
    "- Stores each question temporarily in the variable `q`\n",
    "- Prints a message as if we were sending it to the AI\n",
    "\n",
    "This is the exact kind of structure we’ll use when sending **multiple prompts** to the OpenAI API — but for now, we’re just printing the questions to get used to the idea!\n",
    "\n",
    "**Looping the OpenAI API -**\n",
    "Now that we're comfortable with concept of loops, let's send multiple questions to the OpenAI API using a `for` loop, just like placing several orders at a restaurant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Customer asks: What is 1 + 1?\n",
      "AI (Chef) replies:\n",
      "1 + 1 = **2**.\n",
      "\n",
      "Customer asks: What is the opposite of up?\n",
      "AI (Chef) replies:\n",
      "The opposite of **up** is **down**.\n",
      "\n",
      "Customer asks: What is the capital of France?\n",
      "AI (Chef) replies:\n",
      "The capital of France is **Paris**.\n"
     ]
    }
   ],
   "source": [
    "# Assume client is already set up with your OpenAI API key\n",
    "questions = [\n",
    "    \"What is 1 + 1?\",\n",
    "    \"What is the opposite of up?\",\n",
    "    \"What is the capital of France?\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"\\nCustomer asks: {question}\")\n",
    "\n",
    "    # Send question to the OpenAI model (Chef prepares dish)\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4.1\",\n",
    "        input=question\n",
    "    )\n",
    "\n",
    "    # Get the model's answer (Waiter brings it back)\n",
    "    result = response.output_text\n",
    "    print(\"AI (Chef) replies:\")\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what's happening:\n",
    "1. **We loop through each question** using `for question in questions`.\n",
    "2. For each one:\n",
    "   - We **print the question** (the customer asks).\n",
    "   - We **send the question to the model** using `client.responses.create(...)` (the chef gets to work).\n",
    "   - We **get the answer** from `response.output_text` (the waiter brings the dish back).\n",
    "   - Then we **print the AI's reply**.\n",
    "\n",
    "Just like a waiter taking multiple orders and delivering dishes one at a time, this loop helps us ask several things without repeating our code over and over!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[WARNING]**: Keep in mind that the API does **not remember** your previous question. Each call to the model is **independent**, like asking the chef something new every time, with no memory of past conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First response:\n",
      "That's awesome! Blue is a very popular favorite color—it's often associated with calmness, trust, and creativity. Do you have a specific shade of blue you like best (like navy, sky blue, or turquoise)? Or do you just love all things blue?\n",
      "\n",
      "Second response (no memory):\n",
      "I don’t know your favorite color yet! If you tell me, I’ll remember it for our conversation. What is your favorite color?\n"
     ]
    }
   ],
   "source": [
    "# Demonstrating that the API does NOT have memory between calls\n",
    "\n",
    "# First call: ask a question\n",
    "response1 = client.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    input=\"My favorite color is blue.\"\n",
    ")\n",
    "print(\"First response:\")\n",
    "print(response1.output_text)\n",
    "\n",
    "# Second call: refer to the previous message, but without context\n",
    "response2 = client.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    input=\"What is my favorite color?\"\n",
    ")\n",
    "print(\"\\nSecond response (no memory):\")\n",
    "print(response2.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Endpoints — _“Different Sections of the Menu”_\n",
    "\n",
    "##### In the Restaurant Metaphor:\n",
    "\n",
    "In the restaurant, instead of asking the waiter for everything, you talk to **different workers** for **different tasks**:\n",
    "\n",
    "You tell the waiter what food you want.  \n",
    "You ask the bartender for a drink.  \n",
    "You call the cashier to pay the bill.  \n",
    "\n",
    "Each worker has a specific job, and you contact the right one depending on what you need.\n",
    "\n",
    "That's what an **endpoint** is in programming:  \n",
    "It’s a specific address or route that does one job, like generating text, images, embeddings, transcripts, etc...  You \"go\" to the right endpoint, and it gives you exactly what you asked for.\n",
    "\n",
    "<div style=\"text-align: center; margin: 1em 0;\">\n",
    "  <img src=\"images/image_03.png\" alt=\"Restaurant Analogy\" width=\"400\"/>\n",
    "</div>\n",
    "\n",
    "##### In API Terms:\n",
    "\n",
    "An **endpoint** is a **URL** where you send your request.\n",
    "\n",
    "For example, with the OpenAI API:\n",
    "\n",
    "* `https://api.openai.com/v1/responses` → Talk with ChatGPT, like we just did\n",
    "* `.../embeddings` → Turn text into numbers (useful for search).\n",
    "* `.../images/generations` → Generate images from text.\n",
    "* `.../audio/speech` → Create speech\n",
    "* `.../audio/transcriptions` → Create transcriptions\n",
    "* `.../audio/translations` → Create translations\n",
    "\n",
    "examples are:\n",
    "* response = client.**responses**.create()\n",
    "* response = client.**audio.speech**.create()\n",
    "\n",
    "Each one does **something different**, but they all follow the same rules of ordering.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Speech Endpoint — Text to Audio with Different Voices\n",
    "In this example, we use the OpenAI **Text-to-Speech (TTS)** API to convert a line of text into spoken audio using multiple voices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speech Endpoint\n",
    "from pathlib import Path\n",
    "\n",
    "voices = [\"echo\", \"nova\", \"shimmer\"]\n",
    "input_text = \"Today, we are testing the OpenAI API. At the moment, we are testing the audio API, during a workshop of Tilburg.ai\"\n",
    "#input_text = \"Vandaag testen we de OpenAI API, tijdens een workshop van Tilburg.ai\"\n",
    "\n",
    "for voice in voices:\n",
    "    speech_file_path = Path.cwd() / f\"audio/speech_{voice}.mp3\"\n",
    "    with client.audio.speech.with_streaming_response.create(\n",
    "        model=\"gpt-4o-mini-tts\",\n",
    "        voice=voice,\n",
    "        input=input_text\n",
    "    ) as response:\n",
    "        response.stream_to_file(speech_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What this does**:\n",
    "- **Loops** through 3 voice options: `echo`, `nova`, and `shimmer`\n",
    "- Sends the `input_text` to **OpenAI's speech endpoint**\n",
    "- Streams the audio response and saves it as an `.mp3` file (one per voice)\n",
    "- Files will be saved in: `audio/speech_echo.mp3`, `audio/speech_nova.mp3`, etc.\n",
    "**Make sure you have an `audio/` folder** in the same directory as your notebook or script, or this will raise a `FileNotFoundError`.\n",
    "\n",
    "##### Using the Transcription Endpoint — Speech to Text\n",
    "\n",
    "Now that we’ve generated speech, let’s try the opposite: **transcribing audio back into text** using OpenAI’s transcription API.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today we are testing the OpenAI API. At the moment we are testing the audio API during a workshop of Tilburg AI.\n"
     ]
    }
   ],
   "source": [
    "# Using the transcription endpoint\n",
    "audio_file = open(\"audio/speech_echo.mp3\", \"rb\")\n",
    "transcript = client.audio.transcriptions.create(\n",
    "  model=\"gpt-4o-transcribe\",\n",
    "  file=audio_file,\n",
    "  #language=\"nl\", # Optional: force Dutch if needed\n",
    "  #prompt=\"Everytime you hear Tilburg AI, note it as Tilburg.ai\" # Optional\n",
    ")\n",
    "\n",
    "print(transcript.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What this does:**\n",
    "- Loads the previously generated audio file (from the `echo` voice)\n",
    "- Sends it to OpenAI’s transcription model (`gpt-4o-transcribe`)\n",
    "- Optionally, you can:\n",
    "  - Specify the language with `language=\"nl\"` for Dutch\n",
    "  - Add a custom prompt to guide transcription formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Embeddings Endpoint\n",
    "\n",
    "**What Are Embeddings?**\n",
    "\n",
    "Embeddings are a way to turn text (words, sentences, or even whole documents) into numbers so that computers can understand and work with them. Each piece of text is converted into a long list of numbers (called a _vector_) that captures its meaning and context.\n",
    "\n",
    "- **Why are embeddings useful?**\n",
    "  - They let computers compare how similar two pieces of text are (e.g., \"cat\" and \"kitten\" will have similar embeddings).\n",
    "  - They are used for search, recommendations, clustering, and many other AI tasks.\n",
    "  - Embeddings make it possible to do math with language, like finding analogies or grouping similar ideas together.\n",
    "\n",
    "In the OpenAI API, you can use the embeddings endpoint to get these number representations for your text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0022756963, -0.009305916, 0.015742613, -0.0077253063, -0.0047450014, 0.014917395, -0.009807394, -0.038264707, -0.0069127847, -0.028590616, 0.025251659, 0.018116701, -0.0036309576, -0.02554366, 0.00055543496, -0.016428178, 0.02828592, 0.0054083494, 0.009610611, -0.016415482, -0.015412526, 0.004272088, 0.0069953064, -0.007223828, -0.0039007403, 0.018573744, 0.008734611, -0.022699833, 0.011508612, 0.023893224, 0.015602961, -0.0035706533, -0.034963835, -0.0041514793, -0.026178442, -0.02150644, -0.0057066972, 0.011768873, 0.008455306, 0.004129262, 0.019157745, -0.014358787, 0.008982176, 0.0063605234, -0.04570436, 0.017900875, -0.005570219, -0.0007716578, -0.02215392, -0.0039229575]\n",
      "The embedding is a list of 1536 floats\n"
     ]
    }
   ],
   "source": [
    "# Using the embeddings endpoint\n",
    "response =client.embeddings.create(\n",
    "  model=\"text-embedding-ada-002\",\n",
    "  input=\"The food was delicious and the waiter...\",\n",
    "  encoding_format=\"float\"\n",
    ")\n",
    "\n",
    "print(response.data[0].embedding[:50])\n",
    "print(f\"The embedding is a list of {len(response.data[0].embedding)} floats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokens — “How Much You’re Saying”\n",
    "\n",
    "##### In the Restaurant Metaphor:\n",
    "\n",
    "Imagine you're paying **per word** of your order instead of per item.\n",
    "\n",
    "Saying:\n",
    "\n",
    "> “I want spaghetti.”\n",
    "\n",
    "...costs fewer tokens than:\n",
    "\n",
    "> “Hello kind waiter, I would like a steaming plate of your finest spaghetti, with extra parmesan on top, please.”\n",
    "\n",
    "The **longer** or more **complex** your request, the **more tokens** it costs.\n",
    "\n",
    "\n",
    "##### In OpenAI Terms:\n",
    "\n",
    "- **Tokens = Small chunks of text**, usually a word or part of a word.\n",
    "- Examples:\n",
    "  - `\"Hello\"` → 1 token  \n",
    "  - `\"Artificial intelligence is amazing!\"` → ~5 tokens\n",
    "\n",
    "\n",
    "**Why Tokens Matter:**\n",
    "\n",
    "- You **pay per token** — for both **input** (your prompt) and **output** (the AI’s reply).\n",
    "- Each model has a **maximum token limit per request**  \n",
    "  _(e.g., GPT-4o supports up to ~128,000 tokens)._\n",
    "- **Shorter, clearer prompts** = faster, cheaper, and often better results.\n",
    "\n",
    "📌 **Takeaway**: Think of tokens like paying by the word — be thoughtful, but concise!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Token usage:\n",
      "Input tokens: 23\n",
      "Output tokens: 447\n",
      "Total tokens: 470\n",
      "First 5 token strings: [' Let', '’s', ' break', ' down', ' **', 'API', ' calls', '**']\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "prompt = \"Explain API calls in simple terms, using the customer - waiter - chef metaphor.\"\n",
    "\n",
    "# Make the API call (Chef prepares the meal)\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    input=prompt\n",
    ")\n",
    "\n",
    "output_text = response.output_text\n",
    "\n",
    "# Show token usage\n",
    "print(\"\\nToken usage:\")\n",
    "print(\"Input tokens:\", response.usage.input_tokens)\n",
    "print(\"Output tokens:\", response.usage.output_tokens)\n",
    "print(\"Total tokens:\", response.usage.total_tokens)\n",
    "\n",
    "# Choose the encoding for your model (e.g., \"cl100k_base\" for GPT-4/3.5-turbo)\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# Tokenize the output text\n",
    "tokens = encoding.encode(output_text)\n",
    "\n",
    "# To see the actual strings for those tokens:\n",
    "print(\"First 5 token strings:\", [encoding.decode([t]) for t in tokens[2:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total cost: $0.003622\n"
     ]
    }
   ],
   "source": [
    "# Add cost calculation, $2.00 / 1M input tokens, $8.00 / 1M output tokens\n",
    "cost_per_million_input_tokens = 2\n",
    "cost_per_million_output_tokens = 8\n",
    "\n",
    "total_cost = (response.usage.input_tokens / 1000000) * cost_per_million_input_tokens + \\\n",
    "             (response.usage.output_tokens / 1000000) * cost_per_million_output_tokens\n",
    "\n",
    "print(f\"\\nTotal cost: ${total_cost:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From ChatGPT to Azure OpenAI — Steps Toward More Control\n",
    "\n",
    "When using AI tools, especially in research, **data privacy and control** matter. Here's a quick overview of how the different access methods to OpenAI models compare in terms of data handling:\n",
    "\n",
    "\n",
    "##### 1. **ChatGPT (chat.openai.com)**  \n",
    "By default, data entered here **may be used to improve OpenAI’s models**.  \n",
    "However, you can opt out of training by adjusting your settings — we explain how in this article:  \n",
    "- [ChatGPT & Privacy – Tilburg.ai](https://tilburg.ai/2024/09/chatgpt-privacy/)\n",
    "\n",
    "##### 2. **OpenAI API**  \n",
    "When using the OpenAI API directly, **your data is not used for training** by default.  \n",
    "This gives more control compared to ChatGPT, especially when working with sensitive or research-related data.\n",
    "\n",
    "##### 3. **Azure OpenAI (portal.azure.com)**  \n",
    "For the highest level of control, especially within institutions:\n",
    "**Azure OpenAI** gives you access to OpenAI’s models (like GPT-4) via Microsoft’s Azure cloud\n",
    "This means:\n",
    "\n",
    "- **Data Privacy**  \n",
    "  Your data stays within your Azure environment and is **not used for training**.\n",
    "\n",
    "- **Security & Compliance**  \n",
    "  Built on Azure’s infrastructure with support for enterprise-grade security and compliance requirements.\n",
    "\n",
    "- **Regional Deployment**  \n",
    "  Models can be deployed in **European data centers**, addressing common concerns around sending research data to U.S.-based servers.\n",
    "\n",
    "**Summary:** If you're handling sensitive or regulated data, **moving from ChatGPT to API to Azure OpenAI** is a progression toward **greater privacy, compliance, and control**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using `.env` Variables with Azure OpenAI**\n",
    "\n",
    "Just like with the OpenAI API key, it's important to use a `.env` file when working with Azure OpenAI.\n",
    "\n",
    "When dealing with APIs — especially in cloud environments, it’s considered best practice to **avoid hard-coding sensitive information** (like API keys, endpoints, or version numbers) directly into your script.\n",
    "\n",
    "Instead, we store these values in a hidden `.env` file and access them in the code using `os.getenv()`.  \n",
    "This keeps your credentials secure, your code cleaner, and makes it easier to manage different environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: De stelling van Pythagoras stelt dat in een rechthoekige driehoek de som van de kwadraten van de lengtes van de twee katheten gelijk is aan het kwadraat van de lengte van de hypotenusa. \n",
      "\n",
      "De formule is:\n",
      "\\[ a^2 + b^2 = c^2 \\]\n",
      "\n",
      "waar:\n",
      "- \\( a \\) en \\( b \\) de lengtes van de twee korte zijden (katheten) zijn,\n",
      "- \\( c \\) de lengte van de langste zijde (hypotenusa) is.\n",
      "\n",
      "**Voorbeeld:**\n",
      "\n",
      "Stel je hebt een ladder die tegen een muur staat. De ladder is 5 meter lang, en je wil weten hoe hoog de ladder de muur raakt als de voet van de ladder 3 meter van de muur staat.\n",
      "\n",
      "**Berekening:**\n",
      "\n",
      "1. De lengte van de ladder is de hypotenusa \\( c = 5 \\).\n",
      "2. De afstand van de voet van de ladder tot aan de muur is \\( a = 3 \\).\n",
      "\n",
      "We zoeken de hoogte waarop de ladder de muur raakt, dat is \\( b \\).\n",
      "\n",
      "Volgens de stelling van Pythagoras:\n",
      "\\[ a^2 + b^2 = c^2 \\]\n",
      "\\[ 3^2 + b^2 = 5^2 \\]\n",
      "\\[ 9 + b^2 = 25 \\]\n",
      "\\[ b^2 = 25 - 9 = 16 \\]\n",
      "\\[ b = \\sqrt{16} = 4 \\]\n",
      "\n",
      "**Resultaat:**\n",
      "\n",
      "De ladder raakt de muur 4 meter hoog.\n",
      "\n",
      "**Gebruik in het dagelijks leven:**\n",
      "\n",
      "- Calculeren van de hoogte van gebouwen of torens.\n",
      "- Bepalen van de afstand tussen twee punten op een terrein.\n",
      "- Planning en ontwerp bij bouwprojecten en infrastructuur.\n",
      "\n",
      "Heeft u nog een specifiek voorbeeld of toepassing in gedachten?\n"
     ]
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "load_dotenv()\n",
    "    \n",
    "azure_client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "    api_version=os.getenv(\"API_VERSION\"),\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    )\n",
    "    \n",
    "deployment_name=os.getenv(\"MODEL_VERSION\")\n",
    "    \n",
    "# For all possible arguments see https://platform.openai.com/docs/api-reference/chat-completions/create\n",
    "response = azure_client.chat.completions.create(\n",
    "    model=deployment_name,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Knock knock.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who's there?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Lettuce.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Give me an example of the stelling van Pythagoras and how to use it in real life\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"{response.choices[0].message.role}: {response.choices[0].message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Case Study: Finding Similar Scientific Texts Using Embeddings\n",
    "\n",
    "In this case study, we demonstrate how to use **OpenAI embeddings** to search for the most relevant scientific text snippet from a collection — based on a user’s query.\n",
    "\n",
    "##### What We’ll Do:\n",
    "\n",
    "1. **Embed** a list of scientific text snippets.\n",
    "2. **Embed** the search query.\n",
    "3. **Calculate similarity** between the query embedding and each text embedding.\n",
    "4. **Identify and return** the most similar text snippet.\n",
    "\n",
    "This approach is useful for tasks like semantic search, content recommendation, or academic literature retrieval.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Tell me about plants creating food from sunlight.\n",
      "\n",
      "Most similar article:\n",
      "\n",
      "Photosynthesis is the process by which green plants and some other organisms use sunlight to synthesize foods with the help of chlorophyll. During photosynthesis in green plants, light energy is captured and used to convert water, carbon dioxide, and minerals into oxygen and energy-rich organic compounds.\n",
      "\n",
      "Similarity score: 0.8761\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Case Study: Finding Similar Scientific Texts\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# The list of scientific articles is assumed to be defined in a previous cell\n",
    "scientific_articles = [\n",
    "    \"Photosynthesis is the process by which green plants and some other organisms use sunlight to synthesize foods with the help of chlorophyll. During photosynthesis in green plants, light energy is captured and used to convert water, carbon dioxide, and minerals into oxygen and energy-rich organic compounds.\",\n",
    "\n",
    "    \"Gravity is a fundamental force of nature that causes objects with mass or energy to be attracted to each other. It is responsible for phenomena such as the falling of objects to the ground and the orbits of planets around the Sun. The force of gravity is proportional to the product of the two masses and inversely proportional to the square of the distance between their centers.\",\n",
    "    \n",
    "    \"Evolution is the change in the heritable characteristics of biological populations over successive generations. Evolutionary processes give rise to biodiversity at every level of biological organization, including the levels of genes, individual organisms, and the structure and function of ecosystems. Evolutionary biology is a subfield of biology that studies the evolutionary processes that produced the diversity of life on Earth.\"\n",
    "]\n",
    "\n",
    "# Get embeddings for the scientific articles\n",
    "article_embeddings = []\n",
    "for article in scientific_articles:\n",
    "    response = client.embeddings.create(\n",
    "        model=\"text-embedding-ada-002\", # Use the appropriate embedding model\n",
    "        input=article,\n",
    "        encoding_format=\"float\"\n",
    "    )\n",
    "    article_embeddings.append(response.data[0].embedding)\n",
    "\n",
    "# Define a search query\n",
    "query = \"Tell me about plants creating food from sunlight.\"\n",
    "\n",
    "# Get the embedding for the query\n",
    "query_response = client.embeddings.create(\n",
    "    model=\"text-embedding-ada-002\", # Use the same model as for articles\n",
    "    input=query,\n",
    "    encoding_format=\"float\"\n",
    ")\n",
    "query_embedding = query_response.data[0].embedding\n",
    "\n",
    "# Calculate cosine similarity between the query and each article embedding\n",
    "article_embeddings_array = np.array(article_embeddings)\n",
    "query_embedding_array = np.array(query_embedding).reshape(1, -1)\n",
    "\n",
    "similarities = cosine_similarity(query_embedding_array, article_embeddings_array)\n",
    "\n",
    "# Find the index of the most similar article\n",
    "most_similar_article_index = np.argmax(similarities)\n",
    "\n",
    "# Get the most similar article text\n",
    "most_similar_article = scientific_articles[most_similar_article_index]\n",
    "\n",
    "# Print the query and the most similar article\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(f\"Most similar article:\\n\")\n",
    "print(most_similar_article)\n",
    "print(f\"\\nSimilarity score: {similarities[0][most_similar_article_index]:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: ...\n",
      "\n",
      "Most similar article:\n",
      "\n",
      "Gravity is a fundamental force of nature that causes objects with mass or energy to be attracted to each other. It is responsible for phenomena such as the falling of objects to the ground and the orbits of planets around the Sun. The force of gravity is proportional to the product of the two masses and inversely proportional to the square of the distance between their centers.\n",
      "\n",
      "Similarity score: 0.7361\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define a search query\n",
    "query = \"...\"\n",
    "\n",
    "# Get the embedding for the query\n",
    "query_response = client.embeddings.create(\n",
    "    model=\"text-embedding-ada-002\", # Use the same model as for articles\n",
    "    input=query,\n",
    "    encoding_format=\"float\"\n",
    ")\n",
    "query_embedding = query_response.data[0].embedding\n",
    "\n",
    "# Calculate cosine similarity between the query and each article embedding\n",
    "article_embeddings_array = np.array(article_embeddings)\n",
    "query_embedding_array = np.array(query_embedding).reshape(1, -1)\n",
    "\n",
    "similarities = cosine_similarity(query_embedding_array, article_embeddings_array)\n",
    "\n",
    "# Find the index of the most similar article\n",
    "most_similar_article_index = np.argmax(similarities)\n",
    "\n",
    "# Get the most similar article text\n",
    "most_similar_article = scientific_articles[most_similar_article_index]\n",
    "\n",
    "# Print the query and the most similar article\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(f\"Most similar article:\\n\")\n",
    "print(most_similar_article)\n",
    "print(f\"\\nSimilarity score: {similarities[0][most_similar_article_index]:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Wrapping Up — What We've Learned\n",
    "\n",
    "In this workshop, we walked through the all the steps needed to interact with OpenAI's API, from the basics to more advanced use cases.\n",
    "\n",
    "##### Topics We Covered:\n",
    "\n",
    "- What an API is, and how OpenAI's API works\n",
    "- Why and how to securely use your **API key** with a `.env` file\n",
    "- Making your **first API call** using a simple prompt\n",
    "- Looping over multiple questions using Python\n",
    "- Used different endpoints:\n",
    "  - Using **speech synthesis** (text-to-audio) and **transcription** (audio-to-text)\n",
    "  - Used an **embedding** model\n",
    "- Understanding **tokens** — how pricing and length work\n",
    "- Case study of using **embeddings** to find semantically similar scientific texts\n",
    "- Comparing **ChatGPT**, **OpenAI API**, and **Azure OpenAI** in terms of control and data privacy\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
