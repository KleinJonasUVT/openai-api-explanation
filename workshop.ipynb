{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First OpenAI API Call\n",
    "\n",
    "We first show the most basic way to make an API call to OpenAI's GPT model. We'll use a restaurant analogy to explain how API calls work:\n",
    "\n",
    "- **You (Customer)**: The person making the request\n",
    "- **OpenAI API (Waiter)**: The messenger that takes your request to the AI\n",
    "- **GPT Model (Chef)**: The system that processes your request and creates the response\n",
    "\n",
    "In this example, we'll:\n",
    "1. Set up the connection to OpenAI (like finding a restaurant)\n",
    "2. Create a simple prompt (like placing an order)\n",
    "3. Get the response (like receiving your meal)\n",
    "\n",
    "This is the simplest form of an API call - no streaming, no complex parameters, just a basic request and response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waiter: This is the OpenAI API. You talk to it using the 'openai' Python package.\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# Set your OpenAI API key (replace with your actual key or use an environment variable)\n",
    "client = OpenAI(api_key=os.getenv(\"general_API\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from the AI (Chef):\n",
      "Sure! **Photosynthesis** is how plants make their own food.\n",
      "\n",
      "Here’s how it works, step by step:\n",
      "\n",
      "1. **Plants take in sunlight** using their leaves.\n",
      "2. **They absorb water** from the soil through their roots.\n",
      "3. **They take in carbon dioxide** from the air through tiny holes in their leaves.\n",
      "\n",
      "Using energy from the sunlight, **plants mix the water and carbon dioxide together to make a kind of sugar (food) for themselves**. Oxygen is made as a waste product and goes back into the air.\n",
      "\n",
      "So, in short:  \n",
      "**Photosynthesis is how plants use sunlight, water, and air to make food and oxygen.**\n"
     ]
    }
   ],
   "source": [
    "# Customer: This is YOU (or your app). You decide what to ask.\n",
    "prompt = \"Explain photosynthesis in simple terms.\"\n",
    "\n",
    "# Chef: This is the AI model (like GPT-4). It prepares the response based on your request.\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    input=prompt\n",
    ")\n",
    "\n",
    "# The response is delivered back to the customer (you)\n",
    "result = response.output_text\n",
    "print(\"Response from the AI (Chef):\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looping — “Ordering Again and Again”\n",
    "\n",
    "### In the Restaurant Metaphor:\n",
    "\n",
    "Imagine you're really hungry and want to **order multiple dishes**, one after another:\n",
    "\n",
    "* First: you ask for spaghetti.\n",
    "* Then: you ask for a drink.\n",
    "* Then: dessert.\n",
    "\n",
    "That’s **looping** — doing something **over and over again**, usually **with slight changes**.\n",
    "\n",
    "### In Programming/API Terms:\n",
    "\n",
    "Looping is when your program:\n",
    "\n",
    "* Sends **multiple API requests** in a row.\n",
    "* Often in a **`for` loop** or a **`while` loop**.\n",
    "* Each request might ask a different question or use different data.\n",
    "\n",
    "#### Why It’s Useful:\n",
    "\n",
    "* Process a list of texts automatically (e.g., summarizing 100 articles).\n",
    "* Translate a batch of messages.\n",
    "* Chat with the model in turns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is an API?\n",
      "Pretend we're asking the AI...\n",
      "\n",
      "Question: How does a loop work?\n",
      "Pretend we're asking the AI...\n",
      "\n",
      "Question: What are tokens in OpenAI?\n",
      "Pretend we're asking the AI...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Basic Python loop — no API yet\n",
    "questions = [\"What is an API?\", \"How does a loop work?\", \"What are tokens in OpenAI?\"]\n",
    "\n",
    "for q in questions:\n",
    "    print(\"Question:\", q)\n",
    "    print(\"Pretend we're asking the AI...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Customer asks: What is 1 + 1?\n",
      "AI (Chef) replies:\n",
      "1 + 1 = **2**.\n",
      "\n",
      "Customer asks: What is the opposite of up?\n",
      "AI (Chef) replies:\n",
      "The opposite of \"up\" is **\"down.\"**\n",
      "\n",
      "Customer asks: What is the capital of France?\n",
      "AI (Chef) replies:\n",
      "The capital of France is **Paris**.\n"
     ]
    }
   ],
   "source": [
    "# Assume client is already set up with your OpenAI API key\n",
    "questions = [\n",
    "    \"What is 1 + 1?\",\n",
    "    \"What is the opposite of up?\",\n",
    "    \"What is the capital of France?\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"\\nCustomer asks: {question}\")\n",
    "\n",
    "    # Send question to the OpenAI model (Chef prepares dish)\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4.1\",\n",
    "        input=question\n",
    "    )\n",
    "\n",
    "    # Get the model's answer (Waiter brings it back)\n",
    "    result = response.output_text\n",
    "    print(\"AI (Chef) replies:\")\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Endpoints — “Different Sections of the Menu”\n",
    "\n",
    "### In the Restaurant Metaphor:\n",
    "\n",
    "The menu has **sections**:\n",
    "\n",
    "* Appetizers\n",
    "* Main courses\n",
    "* Desserts\n",
    "  Each has its own list of items.\n",
    "\n",
    "These sections are like **endpoints** — **different areas** of the API that handle different **types of requests**.\n",
    "\n",
    "### In API Terms:\n",
    "\n",
    "An **endpoint** is a **URL** where you send your request.\n",
    "\n",
    "For example, with the OpenAI API:\n",
    "\n",
    "* `https://api.openai.com/v1/responses` → Talk with ChatGPT, like we just did\n",
    "* `https://api.openai.com/v1/embeddings` → Turn text into numbers (useful for search).\n",
    "* `https://api.openai.com/v1/images/generations` → Generate images from text.\n",
    "* `https://api.openai.com/v1/audio/speech` → Create speech\n",
    "* `https://api.openai.com/v1/audio/transcriptions` → Create transcriptions\n",
    "* `https://api.openai.com/v1/audio/translations` → Create translations\n",
    "\n",
    "\n",
    "Each one does **something different**, but they all follow the same rules of ordering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the speech endpoint\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "voices = [\"echo\", \"nova\", \"shimmer\"]\n",
    "input_text = \"Today, we are testing the OpenAI API. At the moment, we are testing the audio API.\"\n",
    "\n",
    "for voice in voices:\n",
    "    speech_file_path = Path.cwd() / f\"speech_{voice}.mp3\"\n",
    "    with client.audio.speech.with_streaming_response.create(\n",
    "        model=\"gpt-4o-mini-tts\",\n",
    "        voice=voice,\n",
    "        input=input_text\n",
    "    ) as response:\n",
    "        response.stream_to_file(speech_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today we are testing the OpenAI API. At the moment we are testing the audio API.\n"
     ]
    }
   ],
   "source": [
    "# Using the transcription endpoint\n",
    "\n",
    "audio_file = open(\"speech_echo.mp3\", \"rb\")\n",
    "transcript = client.audio.transcriptions.create(\n",
    "  model=\"gpt-4o-transcribe\",\n",
    "  file=audio_file\n",
    ")\n",
    "\n",
    "print(transcript.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0022756963, -0.009305916, 0.015742613, -0.0077253063, -0.0047450014, 0.014917395, -0.009807394, -0.038264707, -0.0069127847, -0.028590616, 0.025251659, 0.018116701, -0.0036309576, -0.02554366, 0.00055543496, -0.016428178, 0.02828592, 0.0054083494, 0.009610611, -0.016415482, -0.015412526, 0.004272088, 0.0069953064, -0.007223828, -0.0039007403, 0.018573744, 0.008734611, -0.022699833, 0.011508612, 0.023893224, 0.015602961, -0.0035706533, -0.034963835, -0.0041514793, -0.026178442, -0.02150644, -0.0057066972, 0.011768873, 0.008455306, 0.004129262, 0.019157745, -0.014358787, 0.008982176, 0.0063605234, -0.04570436, 0.017900875, -0.005570219, -0.0007716578, -0.02215392, -0.0039229575]\n",
      "The embedding is a list of 1536 floats\n"
     ]
    }
   ],
   "source": [
    "# Using the embeddings endpoint\n",
    "\n",
    "response =client.embeddings.create(\n",
    "  model=\"text-embedding-ada-002\",\n",
    "  input=\"The food was delicious and the waiter...\",\n",
    "  encoding_format=\"float\"\n",
    ")\n",
    "\n",
    "print(response.data[0].embedding[:50])\n",
    "print(f\"The embedding is a list of {len(response.data[0].embedding)} floats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokens — “How Much You’re Saying”\n",
    "\n",
    "### In the Restaurant Metaphor:\n",
    "\n",
    "Imagine you're paying **per word** of your order instead of per item.\n",
    "\n",
    "Saying:\n",
    "\n",
    "> “I want spaghetti.”\n",
    "\n",
    "Costs fewer tokens than:\n",
    "\n",
    "> “Hello kind waiter, I would like a steaming plate of your finest spaghetti, with extra parmesan on top, please.”\n",
    "\n",
    "The **longer** or more **complex** your request, the **more tokens** it costs.\n",
    "\n",
    "### In OpenAI Terms:\n",
    "\n",
    "* **Tokens = Chunks of text**, usually a few characters long.\n",
    "* “Hello” → 1 token.\n",
    "* “Artificial intelligence is amazing!” → \\~5 tokens.\n",
    "\n",
    "#### Why Tokens Matter:\n",
    "\n",
    "* **You pay per token** (for input *and* output).\n",
    "* There’s a **limit per request** (e.g., 128.000 tokens, depending on the model).\n",
    "* Efficient prompts = better performance and lower cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 80 characters of the response:\n",
      "Absolutely! Let’s break down **API calls** using the **customer-waiter-chef** me\n",
      "\n",
      "Token usage:\n",
      "Input tokens: 23\n",
      "Output tokens: 453\n",
      "Total tokens: 476\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Explain API calls in simple terms, using the customer - waiter - chef metaphor.\"\n",
    "\n",
    "# Make the API call (Chef prepares the meal)\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    input=prompt\n",
    ")\n",
    "\n",
    "# Extract response text and token usage\n",
    "output_text = response.output_text\n",
    "\n",
    "print(\"First 80 characters of the response:\")\n",
    "print(output_text[:80])\n",
    "\n",
    "# Show token usage\n",
    "print(\"\\nToken usage:\")\n",
    "print(\"Input tokens:\", response.usage.input_tokens)\n",
    "print(\"Output tokens:\", response.usage.output_tokens)\n",
    "print(\"Total tokens:\", response.usage.total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total cost: $0.003670\n"
     ]
    }
   ],
   "source": [
    "# Add cost calculation, $2.00 / 1M input tokens, $8.00 / 1M output tokens\n",
    "cost_per_million_input_tokens = 2\n",
    "cost_per_million_output_tokens = 8\n",
    "\n",
    "total_cost = (response.usage.input_tokens / 1000000) * cost_per_million_input_tokens + \\\n",
    "             (response.usage.output_tokens / 1000000) * cost_per_million_output_tokens\n",
    "\n",
    "print(f\"\\nTotal cost: ${total_cost:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming\n",
    "\n",
    "Streaming allows you to receive the model's response in real-time, token by token, rather than waiting for the complete response. This is particularly useful for:\n",
    "\n",
    "- Creating more interactive user experiences\n",
    "- Showing progress as the model generates text\n",
    "- Handling long responses more efficiently\n",
    "\n",
    "In this example, we use the `stream=True` parameter in our API call and process the response using a for loop that prints each token as it arrives."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
