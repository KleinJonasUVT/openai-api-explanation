{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install python-dotenv\n",
    "#%pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First OpenAI API Call\n",
    "\n",
    "We first show the most basic way to make an API call to OpenAI's GPT model. We'll use a restaurant analogy to explain how API calls work:\n",
    "\n",
    "- **You (Customer)**: The person making the request\n",
    "- **OpenAI API (Waiter)**: The messenger that takes your request to the AI\n",
    "- **GPT Model (Chef)**: The system that processes your request and creates the response\n",
    "\n",
    "In this example, we'll:\n",
    "1. Set up the connection to OpenAI (like finding a restaurant)\n",
    "2. Create a simple prompt (like placing an order)\n",
    "3. Get the response (like receiving your meal)\n",
    "\n",
    "This is the simplest form of an API call - no streaming, no complex parameters, just a basic request and response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before making your first API call, follow these steps:\n",
    "\n",
    "1. **Install the OpenAI Python package:**\n",
    "   ```bash\n",
    "   pip install openai\n",
    "   ```\n",
    "2. **Store your API key securely:**\n",
    "   - Create a file named `.env` in your project directory.\n",
    "   - Add your API key to this file like so:\n",
    "     ```\n",
    "     OPENAI_API_KEY=sk-...your-key-here...\n",
    "     ```\n",
    "3. **Load your API key in Python:**\n",
    "   - Install the `python-dotenv` package if you haven't already:\n",
    "     ```bash\n",
    "     pip install python-dotenv\n",
    "     ```\n",
    "   - In your Python code, load the `.env` file and access the API key:\n",
    "     ```python\n",
    "     from dotenv import load_dotenv\n",
    "     import os\n",
    "     load_dotenv()\n",
    "     api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "     ```\n",
    "\n",
    "Now you're ready to use the OpenAI API securely in your code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waiter: This is the OpenAI API. You talk to it using the 'openai' Python package.\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Set your OpenAI API key (replace with your actual key or use an environment variable)\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from the AI (Chef):\n",
      "Photosynthesis is the process plants use to make their own food. Here’s how it works in simple terms:\n",
      "\n",
      "1. **Plants take in sunlight** through their leaves.\n",
      "2. **They absorb water** from the soil through their roots.\n",
      "3. **They take in carbon dioxide** from the air.\n",
      "\n",
      "Using sunlight as energy, plants combine the water and carbon dioxide to make **sugar** (their food) and release **oxygen** back into the air.\n",
      "\n",
      "So, photosynthesis is how plants turn sunlight, water, and carbon dioxide into food and oxygen!\n"
     ]
    }
   ],
   "source": [
    "# Customer: This is YOU (or your app). You decide what to ask.\n",
    "prompt = \"Explain photosynthesis in simple terms.\"\n",
    "\n",
    "# Chef: This is the AI model (like GPT-4). It prepares the response based on your request.\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    input=prompt\n",
    ")\n",
    "\n",
    "# The response is delivered back to the customer (you)\n",
    "result = response.output_text\n",
    "print(\"Response from the AI (Chef):\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looping — “Ordering Again and Again”\n",
    "\n",
    "### In the Restaurant Metaphor:\n",
    "\n",
    "Imagine you're really hungry and want to **order multiple dishes**, one after another:\n",
    "\n",
    "* First: you ask for spaghetti.\n",
    "* Then: you ask for a drink.\n",
    "* Then: dessert.\n",
    "\n",
    "That’s **looping** — doing something **over and over again**, usually **with slight changes**.\n",
    "\n",
    "### In Programming/API Terms:\n",
    "\n",
    "Looping is when your program:\n",
    "\n",
    "* Sends **multiple API requests** in a row.\n",
    "* Often in a **`for` loop** or a **`while` loop**.\n",
    "* Each request might ask a different question or use different data.\n",
    "\n",
    "#### Why It’s Useful:\n",
    "\n",
    "* Process a list of texts automatically (e.g., summarizing 100 articles).\n",
    "* Translate a batch of messages.\n",
    "* Chat with the model in turns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretend we're asking the AI...\n",
      "Question: What is 1 + 1? \n",
      "\n",
      "Pretend we're asking the AI...\n",
      "Question: What is the opposite of up? \n",
      "\n",
      "Pretend we're asking the AI...\n",
      "Question: What is the capital of France? \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Basic Python loop — no API yet\n",
    "questions = [\n",
    "    \"What is 1 + 1?\",\n",
    "    \"What is the opposite of up?\",\n",
    "    \"What is the capital of France?\"\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    print(\"Pretend we're asking the AI...\")\n",
    "    print(\"Question:\", q, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Customer asks: What is 1 + 1?\n",
      "AI (Chef) replies:\n",
      "1 + 1 = **2**.\n",
      "\n",
      "Customer asks: What is the opposite of up?\n",
      "AI (Chef) replies:\n",
      "The opposite of **up** is **down**.\n",
      "\n",
      "Customer asks: What is the capital of France?\n",
      "AI (Chef) replies:\n",
      "The capital of France is **Paris**.\n"
     ]
    }
   ],
   "source": [
    "# Assume client is already set up with your OpenAI API key\n",
    "questions = [\n",
    "    \"What is 1 + 1?\",\n",
    "    \"What is the opposite of up?\",\n",
    "    \"What is the capital of France?\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"\\nCustomer asks: {question}\")\n",
    "\n",
    "    # Send question to the OpenAI model (Chef prepares dish)\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4.1\",\n",
    "        input=question\n",
    "    )\n",
    "\n",
    "    # Get the model's answer (Waiter brings it back)\n",
    "    result = response.output_text\n",
    "    print(\"AI (Chef) replies:\")\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[WARNING]:** Keep in mind that the API does not 'remember' your previous question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First response:\n",
      "That's awesome! Blue is a calming and serene color, often associated with the sky and the ocean. Do you like a specific shade of blue, like navy, royal, or turquoise? Or do you just love blue in general?\n",
      "\n",
      "Second response (no memory):\n",
      "I don't have access to your personal preferences or history unless you tell me! If you'd like to share your favorite color, I’d love to hear it and can remember it for our conversation. What is your favorite color?\n"
     ]
    }
   ],
   "source": [
    "# Demonstrating that the API does NOT have memory between calls\n",
    "\n",
    "# First call: ask a question\n",
    "response1 = client.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    input=\"My favorite color is blue.\"\n",
    ")\n",
    "print(\"First response:\")\n",
    "print(response1.output_text)\n",
    "\n",
    "# Second call: refer to the previous message, but without context\n",
    "response2 = client.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    input=\"What is my favorite color?\"\n",
    ")\n",
    "print(\"\\nSecond response (no memory):\")\n",
    "print(response2.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Endpoints — “Different Sections of the Menu”\n",
    "\n",
    "### In the Restaurant Metaphor:\n",
    "\n",
    "The menu has **sections**:\n",
    "\n",
    "* Appetizers\n",
    "* Main courses\n",
    "* Desserts\n",
    "  \n",
    "Each has its own list of items.\n",
    "\n",
    "These sections are like **endpoints** — **different areas** of the API that handle different **types of requests**.\n",
    "\n",
    "### In API Terms:\n",
    "\n",
    "An **endpoint** is a **URL** where you send your request.\n",
    "\n",
    "For example, with the OpenAI API:\n",
    "\n",
    "* `https://api.openai.com/v1/responses` → Talk with ChatGPT, like we just did\n",
    "* `.../embeddings` → Turn text into numbers (useful for search).\n",
    "* `.../images/generations` → Generate images from text.\n",
    "* `.../audio/speech` → Create speech\n",
    "* `.../audio/transcriptions` → Create transcriptions\n",
    "* `.../audio/translations` → Create translations\n",
    "\n",
    "examples are:\n",
    "* response = client.**responses**.create()\n",
    "* response = client.**audio.speech**.create()\n",
    "\n",
    "Each one does **something different**, but they all follow the same rules of ordering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the speech endpoint\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "voices = [\"echo\", \"nova\", \"shimmer\"]\n",
    "input_text = \"Today, we are testing the OpenAI API. At the moment, we are testing the audio API, during a workshop of Tilburg.ai\"\n",
    "#input_text = \"Vandaag testen we de OpenAI API, tijdens een workshop van Tilburg.ai\"\n",
    "\n",
    "for voice in voices:\n",
    "    speech_file_path = Path.cwd() / f\"speech_{voice}.mp3\"\n",
    "    with client.audio.speech.with_streaming_response.create(\n",
    "        model=\"gpt-4o-mini-tts\",\n",
    "        voice=voice,\n",
    "        input=input_text\n",
    "    ) as response:\n",
    "        response.stream_to_file(speech_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today we are testing the OpenAI API. At the moment, we are testing the audio API during a workshop of Tilburg.ai.\n"
     ]
    }
   ],
   "source": [
    "# Using the transcription endpoint\n",
    "\n",
    "audio_file = open(\"speech_echo.mp3\", \"rb\")\n",
    "transcript = client.audio.transcriptions.create(\n",
    "  model=\"gpt-4o-transcribe\",\n",
    "  file=audio_file,\n",
    "  #language=\"nl\",\n",
    "  prompt=\"Everytime you hear Tilburg AI, note it as Tilburg.ai\"\n",
    ")\n",
    "\n",
    "print(transcript.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Are Embeddings?\n",
    "\n",
    "Embeddings are a way to turn text (words, sentences, or even whole documents) into numbers so that computers can understand and work with them. Each piece of text is converted into a long list of numbers (called a vector) that captures its meaning and context.\n",
    "\n",
    "- **Why are embeddings useful?**\n",
    "  - They let computers compare how similar two pieces of text are (e.g., \"cat\" and \"kitten\" will have similar embeddings).\n",
    "  - They are used for search, recommendations, clustering, and many other AI tasks.\n",
    "  - Embeddings make it possible to do math with language, like finding analogies or grouping similar ideas together.\n",
    "\n",
    "In the OpenAI API, you can use the embeddings endpoint to get these number representations for your text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0022756963, -0.009305916, 0.015742613, -0.0077253063, -0.0047450014, 0.014917395, -0.009807394, -0.038264707, -0.0069127847, -0.028590616, 0.025251659, 0.018116701, -0.0036309576, -0.02554366, 0.00055543496, -0.016428178, 0.02828592, 0.0054083494, 0.009610611, -0.016415482, -0.015412526, 0.004272088, 0.0069953064, -0.007223828, -0.0039007403, 0.018573744, 0.008734611, -0.022699833, 0.011508612, 0.023893224, 0.015602961, -0.0035706533, -0.034963835, -0.0041514793, -0.026178442, -0.02150644, -0.0057066972, 0.011768873, 0.008455306, 0.004129262, 0.019157745, -0.014358787, 0.008982176, 0.0063605234, -0.04570436, 0.017900875, -0.005570219, -0.0007716578, -0.02215392, -0.0039229575]\n",
      "The embedding is a list of 1536 floats\n"
     ]
    }
   ],
   "source": [
    "# Using the embeddings endpoint\n",
    "\n",
    "response =client.embeddings.create(\n",
    "  model=\"text-embedding-ada-002\",\n",
    "  input=\"The food was delicious and the waiter...\",\n",
    "  encoding_format=\"float\"\n",
    ")\n",
    "\n",
    "print(response.data[0].embedding[:50])\n",
    "print(f\"The embedding is a list of {len(response.data[0].embedding)} floats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokens — “How Much You’re Saying”\n",
    "\n",
    "### In the Restaurant Metaphor:\n",
    "\n",
    "Imagine you're paying **per word** of your order instead of per item.\n",
    "\n",
    "Saying:\n",
    "\n",
    "> “I want spaghetti.”\n",
    "\n",
    "Costs fewer tokens than:\n",
    "\n",
    "> “Hello kind waiter, I would like a steaming plate of your finest spaghetti, with extra parmesan on top, please.”\n",
    "\n",
    "The **longer** or more **complex** your request, the **more tokens** it costs.\n",
    "\n",
    "### In OpenAI Terms:\n",
    "\n",
    "* **Tokens = Chunks of text**, usually a few characters long.\n",
    "* “Hello” → 1 token.\n",
    "* “Artificial intelligence is amazing!” → \\~5 tokens.\n",
    "\n",
    "#### Why Tokens Matter:\n",
    "\n",
    "* **You pay per token** (for input *and* output).\n",
    "* There’s a **limit per request** (e.g., 128.000 tokens, depending on the model).\n",
    "* Efficient prompts = better performance and lower cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Token usage:\n",
      "Input tokens: 23\n",
      "Output tokens: 365\n",
      "Total tokens: 388\n",
      "First 5 token strings: [' Let', '’s', ' use', ' the', ' **', 'customer', '-w', 'ait']\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "prompt = \"Explain API calls in simple terms, using the customer - waiter - chef metaphor.\"\n",
    "\n",
    "# Make the API call (Chef prepares the meal)\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    input=prompt\n",
    ")\n",
    "\n",
    "output_text = response.output_text\n",
    "\n",
    "# Show token usage\n",
    "print(\"\\nToken usage:\")\n",
    "print(\"Input tokens:\", response.usage.input_tokens)\n",
    "print(\"Output tokens:\", response.usage.output_tokens)\n",
    "print(\"Total tokens:\", response.usage.total_tokens)\n",
    "\n",
    "# Choose the encoding for your model (e.g., \"cl100k_base\" for GPT-4/3.5-turbo)\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# Tokenize the output text\n",
    "tokens = encoding.encode(output_text)\n",
    "\n",
    "# To see the actual strings for those tokens:\n",
    "print(\"First 5 token strings:\", [encoding.decode([t]) for t in tokens[2:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total cost: $0.002966\n"
     ]
    }
   ],
   "source": [
    "# Add cost calculation, $2.00 / 1M input tokens, $8.00 / 1M output tokens\n",
    "cost_per_million_input_tokens = 2\n",
    "cost_per_million_output_tokens = 8\n",
    "\n",
    "total_cost = (response.usage.input_tokens / 1000000) * cost_per_million_input_tokens + \\\n",
    "             (response.usage.output_tokens / 1000000) * cost_per_million_output_tokens\n",
    "\n",
    "print(f\"\\nTotal cost: ${total_cost:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure OpenAI\n",
    "\n",
    "Azure OpenAI is Microsoft's cloud service that provides access to OpenAI's models (like GPT-4) through Azure's infrastructure.\n",
    "\n",
    "- **Data Privacy**: Your data stays within your Azure environment and isn't used to train models\n",
    "- **Security**: Integration with Azure's security features and compliance certifications\n",
    "- **Regional Availability**: You can deploy models in specific Azure regions to meet data residency requirements, so deploying it in a European region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: Absolutely! The **stelling van Pythagoras** (the Pythagorean theorem) states:\n",
      "\n",
      "In a right triangle, the square of the length of the hypotenuse (the side opposite the right angle) is equal to the sum of the squares of the lengths of the other two sides.\n",
      "\n",
      "In formula form:  \n",
      "\\[ a^2 + b^2 = c^2 \\]  \n",
      "where **a** and **b** are the sides that form the right angle, and **c** is the hypotenuse.\n",
      "\n",
      "## Example\n",
      "\n",
      "Suppose you have a right triangle with sides **a = 3 meters** and **b = 4 meters**. What is the length of the hypotenuse (**c**)?\n",
      "\n",
      "**Solution:**\n",
      "\n",
      "\\[\n",
      "a^2 + b^2 = c^2 \\\\\n",
      "3^2 + 4^2 = c^2 \\\\\n",
      "9 + 16 = c^2 \\\\\n",
      "25 = c^2 \\\\\n",
      "c = \\sqrt{25} = 5\n",
      "\\]\n",
      "\n",
      "So, the hypotenuse is **5 meters**.\n",
      "\n",
      "---\n",
      "\n",
      "## Real-life example: Ladder against a wall\n",
      "\n",
      "Imagine you need to place a ladder against a wall. The foot of the ladder is **3 meters** away from the wall, and you want the ladder to reach a window that is **4 meters** high. How long does the ladder need to be?\n",
      "\n",
      "- The distance from the base of the wall to the top of the window: **4 meters** (vertical side)\n",
      "- The distance from the wall to the foot of the ladder: **3 meters** (horizontal side)\n",
      "- The length of the ladder: **c** (hypotenuse)\n",
      "\n",
      "Using the stelling van Pythagoras:\n",
      "\n",
      "\\[\n",
      "c^2 = 3^2 + 4^2 = 9 + 16 = 25 \\\\\n",
      "c = 5\n",
      "\\]\n",
      "\n",
      "So, you need a ladder of **at least 5 meters** to safely reach the window.\n",
      "\n",
      "---\n",
      "\n",
      "**Summary:**  \n",
      "The stelling van Pythagoras is super useful in construction, navigation, and anywhere you need to calculate distances in right triangles!\n"
     ]
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "    \n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "    api_version=os.getenv(\"API_VERSION\"),\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    )\n",
    "    \n",
    "deployment_name=os.getenv(\"MODEL_VERSION\")\n",
    "    \n",
    "# For all possible arguments see https://platform.openai.com/docs/api-reference/chat-completions/create\n",
    "response = client.chat.completions.create(\n",
    "    model=deployment_name,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Knock knock.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who's there?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Lettuce.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Give me an example of the stelling van Pythagoras and how to use it in real life\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"{response.choices[0].message.role}: {response.choices[0].message.content}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
